## Improving Quality and Diversity of GAN Image Generation through Cosine Similarity-Based Diversity Loss(CosDivGAN) <br><sub>Official PyTorch implementation of the KIICE 2025 paper</sub>
### <b>Abstract</b> <br>
Generative Adversarial Networks (GANs) are among the most widely known models in the field of image generation. However, existing GAN models often struggle to balance high-quality image generation with diverse image production. This study proposes a cosine similarity-based diversity loss technique to simultaneously enhance both the quality and diversity of generated images. The proposed method measures the similarity between generated images in the intermediate feature space of the discriminator and applies adaptive weights by comparing this similarity to that of real images. Experiments are conducted on the CelebA and LSUN datasets, and the effectiveness of the proposed method is verified through comparisons with DCGAN, WGAN-GP, and MSGAN. The proposed GAN, which incorporates this technique into the DCGAN architecture, achieves an FID score of 18.69 on the CelebA dataset and shows an 7.6% improvement in MS-SSIM score, demonstrating superior performance in both image quality and diversity compared to existing GAN models.
